{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exponential data 02\n",
    "\n",
    "# _Josep Fortiana_ $\\hskip6cm$ 2022-03-28\n",
    "\n",
    "## Modelling Earthquake Waiting Times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data and explanations, from [Tutorial on Bayesian Data Analysis by Ankit Tewari](https://rstudio-pubs-static.s3.amazonaws.com/370794_abaf71444ad04cd0b05c0a8d41b4de98.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to practise how to model the waiting times between serious earthquakes using a bayesian approach. The United States Geological Survey maintains a list of significant earthquakes worldwide. We will model the rate of earthquakes of magnitude 4.0+ in the state of California during 2015. An iid exponential model on the waiting time between significant earthquakes is appropriate if we assume:\n",
    "\n",
    "1. Earthquake events are independent,\n",
    "2. The rate at which earthquakes occur does not change during the year, and \n",
    "3. The earthquake hazard rate does not change (i.e., the probability of an earthquake happening tomorrow is constant regardless of whether the previous earthquake was yesterday or 100 days ago)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earthquake data:\n",
    "\n",
    "The significant earthquakes of magnitude 4.0+ in the state of California during 2015 occurred on the following dates :\n",
    "\n",
    "January 4, January 20, January 28, May 22, July 21, July 25, August 17, September 16, December 30. \n",
    "\n",
    "Let $Y_{i}$ denote the waiting time in days between the $i$-th earthquake and the following earthquake. Our model is \n",
    "\n",
    "$$\n",
    "    Y_{i}\\mskip8mu\\text{i.i.d.}\\sim\\mskip8mu\\operatorname{Exponential}(\\lambda),\n",
    "$$\n",
    "\n",
    "where the expected waiting time between earthquakes is $\\operatorname{E}(Y)=1/\\lambda$ days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume the conjugate prior $\\lambda\\sim\\operatorname{Gamma}(\\alpha,\\beta)$. Suppose our prior expectation for $\\lambda$ is $1/30$, and we wish to use a prior effective sample size of one interval between earthquakes.\n",
    "\n",
    "A good question then is that what is the value of $\\alpha$ and $\\beta$ so that we can use them in our prior distribution? Well, as you might have guessed, we can use $\\alpha=1$ and $\\beta=30$. It is so because in the exponential-gamma model, $\\alpha$ is the prior effective sample size and the prior mean is $\\alpha/\\beta=1/30$, and since we know the effective sample size $\\alpha=1$, we have $\\beta=30$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason why $\\alpha$ is called _prior effective sample size_ is the updating formula. If  the prior pdf for $\\lambda$ is a $\\operatorname{Gamma}$ with parameters $\\alpha$ and $\\beta$, and an experiment is performed, taking $n$ independent exponential observations $y=(y_{1},\\dots,y_{n})$ with average $\\overline{y}$, the posterior pdf for $\\lambda$ is a $\\operatorname{Gamma}$ with parameters $\\alpha'$ and $\\beta'$:\n",
    "\n",
    "$$\n",
    "    \\left\\{\n",
    "    \\begin{array}{lcl}\n",
    "    \\alpha'&=&\\alpha+n,\\\\\n",
    "    \\beta'&=&\\beta+n\\,\\overline{y}.\n",
    "    \\end{array}\\right.\n",
    "$$\n",
    "\n",
    "thus we might think of the prior pdf as information from $n_{0}=\\alpha$ virtual observations with average $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following is our data vector? The first of the following:\n",
    "\n",
    "$$\n",
    "    \\begin{array}{lcl}\n",
    "    y &= &(16, 8, 114, 60, 4, 23, 30, 105),\\\\\n",
    "    y &= &(3, 16, 8, 114, 60, 4, 23, 30, 105, 1),\\\\\n",
    "    y &= &(3, 16, 8, 114, 60, 4, 23, 30, 105).\n",
    "    \\end{array}\n",
    "$$\n",
    "\n",
    "Recall that we are modeling the waiting times between earthquakes in days. There are eight intervals between the first and last event. We are excluding four days of the year in which no events were observed. A more comprehensive model (e.g., censoring methods) would account for the fact that there were no major earthquakes Jan. 1 to Jan. 4 and Dec. 30 to Dec. 31. This is beyond the scope of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.a<-1\n",
    "prior.b<-30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.1. Simulate from the prior pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N<-10000\n",
    "Sim.lambda.prior<-rgamma(N,prior.a,prior.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theor.lambda.mean<-prior.a/prior.b\n",
    "# Theor.lambda.mode<-(prior.a-1)/prior.b  # For alpha>1, 0 for alpha=1.\n",
    "Theor.lambda.var<-prior.a/prior.b^2\n",
    "Theor.lambda.sd<-sqrt(Theor.lambda.var)\n",
    "round(Theor.lambda.mean,4)\n",
    "round(Theor.lambda.var,4)\n",
    "round(Theor.lambda.sd,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram, compare with the theoretical Gamma pdf \n",
    "options(repr.plot.width=7,repr.plot.height=7)\n",
    "hist(Sim.lambda.prior,freq=FALSE,col=\"LightGreen\",xlab=expression(lambda),ylim=c(0,30),breaks=25)\n",
    "v<-seq(0,max(Sim.lambda.prior),length=1000)\n",
    "lines(v,dgamma(v,shape=prior.a,rate=prior.b),lwd=2.5,col=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.2. Simulate from the prior predictive pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior predictive joint pdf, for an $n$-sample, is:\n",
    "\n",
    "$$\n",
    "f(y_{1},\\dots,y_{n})=\\dfrac{\\Gamma(\\alpha+n)}{\\Gamma(\\alpha)}\n",
    "\t\\cdot\\dfrac{\\beta^{\\alpha}}{(n\\,\\overline{y}+\\beta)^{\\alpha+n}},\\mskip20mu\n",
    "\t\t\t\t\t\ty_{1}>0,\\dots,y_{n}>0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use it for $n=1$, to check a single observation from this distribution,\n",
    "\n",
    "$$\n",
    "f(y)=\\dfrac{\\Gamma(\\alpha+1)}{\\Gamma(\\alpha)}\n",
    "\t\\cdot\\dfrac{\\beta^{\\alpha}}{(y+\\beta)^{\\alpha+1}}\n",
    "    =\\alpha\\cdot\\dfrac{\\beta^{\\alpha}}{(y+\\beta)^{\\alpha+1}},\\mskip20mu y>0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the predictive distribution is a [Pareto II (Lomax)](https://en.wikipedia.org/wiki/Lomax_distribution). The expectation is:\n",
    "\n",
    "$$\n",
    "    \\operatorname{E}(Y)=\\dfrac{\\beta}{\\alpha-1},\\mskip20mu\\alpha>1,\\mskip30mu\n",
    "    \\operatorname{var}(Y)=\\dfrac{\\beta^{2}\\,\\alpha}{(\\alpha-1)^{2}\\,(\\alpha-2)},\\mskip20mu \\alpha>2,\n",
    "$$\n",
    "\n",
    "The Lomax distribution is a special case of the [generalized Pareto distribution](https://en.wikipedia.org/wiki/Generalized_Pareto_distribution). \n",
    "\n",
    "$$\n",
    "    f_{(\\mu,\\sigma,\\xi)}(y)=\\dfrac{1}{\\sigma}\n",
    "    \\left(1+\\dfrac{\\xi\\,(y-\\mu)}{\\sigma }\\right)^{\\left(-{\\frac {1}{\\xi}}-1\\right)},\n",
    "$$\n",
    "\n",
    "where the support is  $y\\geq\\mu$ when $\\xi\\geq0$, and $\\mu\\leq y\\leq\\mu-\\sigma/\\xi$ when  $\\xi<0$. Specifically:\n",
    "\n",
    "$$\n",
    "    \\mu =0,\\mskip20mu \\xi =\\dfrac{1}{\\alpha},\\mskip20mu \\sigma=\\dfrac{\\beta}{\\alpha}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theor.pred.pdf<-function(y,a,b){return(ifelse(y>0,a*b^{a}/(y+b)^(a+1),0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate from the prior predictive. Likelihood is exponential with parameter lambda\n",
    "Sim.y<-rexp(N,rate=Sim.lambda.prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(Sim.y)\n",
    "summary(Sim.y)\n",
    "q.Sim.y<-quantile(Sim.y,c(0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9))\n",
    "round(q.Sim.y,2)\n",
    "ymax<-max(q.Sim.y)\n",
    "round(ymax,2)\n",
    "Sim.y.trunc<-Sim.y[Sim.y<ymax]  # truncate in order to be able to plot the histogram\n",
    "str(Sim.y.trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no theoretical expectation nor variance, as prior.a=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot histogram, \n",
    "options(repr.plot.width=6,repr.plot.height=5)\n",
    "ymax<-max(q.Sim.y)\n",
    "u<-seq(0,ymax,length=1000)\n",
    "yu<-Theor.pred.pdf(u,a=prior.a,b=prior.b)\n",
    "hist(Sim.y.trunc,freq=FALSE,col=\"LightGreen\",breaks=c(min(Sim.y.trunc),q.Sim.y,max(Sim.y.trunc)),ylim=c(0,0.040))\n",
    "lines(u,yu,lwd=2.5,col=\"DarkGreen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.3. Simulate from the posterior pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y<-c(16, 8, 114, 60, 4, 23, 30, 105)\n",
    "n<-length(y)\n",
    "ybar<-mean(y)\n",
    "round(ybar,2)\n",
    "nybar<-sum(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior pdf is $\\lambda\\sim\\operatorname{Gamma}(\\alpha',\\beta')$,\n",
    "\n",
    "$$\n",
    "    \\left\\{\n",
    "    \\begin{array}{lcl}\n",
    "    \\alpha'&=&\\alpha+n,\\\\[0.2cm]\n",
    "    \\beta'&=&\\beta+n\\,\\overline{y}.\n",
    "    \\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post.a<-prior.a+n\n",
    "post.b<-prior.b+nybar\n",
    "post.a\n",
    "post.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theor.lambda.post.mean<-post.a/post.b\n",
    "Theor.lambda.post.mode<-(post.a-1)/post.b  # For alpha>1, 0 for alpha=1.\n",
    "Theor.lambda.post.var<-post.a/post.b^2\n",
    "Theor.lambda.post.sd<-sqrt(Theor.lambda.post.var)\n",
    "round(Theor.lambda.post.mean,4)\n",
    "round(Theor.lambda.post.mode,4)\n",
    "round(Theor.lambda.post.var,6)\n",
    "round(Theor.lambda.post.sd,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1<-10000 \n",
    "Sim.lambda.post<-rgamma(N1,post.a,post.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well understood, this is _not_ an actual posterior sample, it is a sample from the distribution we _know_ will be the posterior, from the theory of conjugate pairs.\n",
    "\n",
    "If we wanted to draw a _real_ posterior sample, we should take $N_{1}$ samples from the prior pdf, then use them to obtain $N_{1}$ $n$-samples of $y=(y_{1},\\dots,y_{n})$, compute $\\overline{y}$ for each of them, discard those with $\\overline{y}\\neq\\overline{y}_{\\text{obs}}$, finally keeping the remaining $N_{2}$, say, samples.\n",
    "\n",
    "#### Exercise: \n",
    "\n",
    "Do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Your code\n",
    "#\n",
    "N2<-N1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram, superimpose the Gamma pdf \n",
    "options(repr.plot.width=6,repr.plot.height=6)\n",
    "v<-seq(0,max(Sim.lambda.post),length=1000)\n",
    "yv<-dgamma(v,shape=post.a,rate=post.b)\n",
    "max.yv<-max(yv)\n",
    "hist(Sim.lambda.post,freq=FALSE,col=\"LightGreen\",xlab=expression(lambda),ylim=c(0,max.yv*1.1),breaks=25)\n",
    "lines(v,yv,lwd=2.5,col=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.4. Simulate from the posterior predictive pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate from the prior predictive. Likelihood is exponential with parameter lambda\n",
    "Sim.y.pred<-rexp(N2,rate=Sim.lambda.post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(Sim.y)\n",
    "summary(Sim.y.pred)\n",
    "q.Sim.y.pred<-quantile(Sim.y.pred,c(0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9))\n",
    "round(q.Sim.y.pred,2)\n",
    "ymax<-max(q.Sim.y.pred)\n",
    "round(ymax,2)\n",
    "Sim.y.pred.trunc<-Sim.y.pred[Sim.y.pred<ymax]  # truncate in order to be able to plot the histogram\n",
    "str(Sim.y.pred.trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theor.post.E.y<-post.b/(post.a-1)\n",
    "Theor.post.var.y<-post.b^2*post.a/((post.a-1)^2*(post.a-2))\n",
    "Theor.post.sd.y<-sqrt(Theor.post.var.y)\n",
    "round(Theor.post.E.y,3)\n",
    "round(Theor.post.var.y,3)\n",
    "round(Theor.post.sd.y,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot histogram, \n",
    "options(repr.plot.width=6,repr.plot.height=5)\n",
    "u<-seq(0,ymax,length=1000)\n",
    "yu<-Theor.pred.pdf(u,a=post.a,b=post.b)\n",
    "ymax<-max(yu)\n",
    "hist(Sim.y.pred.trunc,freq=FALSE,col=\"LightGreen\",\n",
    "     breaks=c(min(Sim.y.pred.trunc),q.Sim.y.pred,max(Sim.y.pred.trunc)),ylim=c(0,ymax*1.1))\n",
    "lines(u,yu,lwd=2.5,col=\"DarkGreen\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
